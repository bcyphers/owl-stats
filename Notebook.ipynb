{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "ix_cols = ['esports_match_id', 'map_name', 'team_name', 'hero_name', 'stat_name']\n",
    "dedup_cols = ix_cols + ['player_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "\n",
    "raw_url = 'https://assets.blz-contentstack.com/v3/assets/blt321317473c90505c/blt911ac3940a7d4e9a/5f31adf8381cf85557b082d0/phs_2020.zip'\n",
    "map_url = 'https://assets.blz-contentstack.com/v3/assets/blt321317473c90505c/blt6471156f88f29f7b/5f31adf38775a353ccc47fb4/match_map_stats.zip'\n",
    "urllib.request.urlretrieve(raw_url, './phs_2020.zip')\n",
    "urllib.request.urlretrieve(map_url, './match_map_stats.zip')\n",
    "\n",
    "with ZipFile('./phs_2020.zip', 'r') as zipObj:\n",
    "   zipObj.extractall()\n",
    "\n",
    "with ZipFile('./match_map_stats.zip', 'r') as zipObj:\n",
    "   zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw statistical data\n",
    "raw_df = pd.read_csv('./phs_2020_1.csv')\n",
    "raw_df = raw_df.append(pd.read_csv('./phs_2020_2.csv'))\n",
    "\n",
    "# get rid of duplicates\n",
    "raw_df = raw_df.drop_duplicates()\n",
    "raw_df_mi = raw_df.set_index(dedup_cols)\n",
    "raw_df = raw_df[~raw_df_mi.index.duplicated(keep='first')]\n",
    "\n",
    "# drop null stats\n",
    "raw_df = raw_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load data about map results\n",
    "map_df = pd.read_csv('./match_map_stats.csv')\n",
    "\n",
    "# Figure out who won each map of each match\n",
    "def is_win(x):\n",
    "    r = x.iloc[0]\n",
    "    m = map_df[(map_df.match_id == r.esports_match_id) \n",
    "               & (map_df.map_name == r.map_name)]\n",
    "    return r.team_name == m.iloc[0]['map_winner']\n",
    "\n",
    "# win or loss for each match/map/team\n",
    "outcomes = raw_df.groupby(['esports_match_id', 'map_name', 'team_name']).apply(is_win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate out stats into counting stats (e.g. damage) and ratio stats (e.g. accuracy)\n",
    "avg_stats = set()\n",
    "stopwords = [' per ', 'efficiency', 'accuracy', 'percentage', 'percent of', ' rate', 'average']\n",
    "for s in set(raw_df['stat_name']):\n",
    "    for sw in stopwords:\n",
    "        if sw in s.lower():\n",
    "            avg_stats.add(s)\n",
    "\n",
    "# we only care about cumulative stats right now, we'll do our own normalizing\n",
    "cum_stats = set(raw_df['stat_name']) - avg_stats\n",
    "\n",
    "# Filter out average stats from the raw data\n",
    "gb = raw_df[raw_df.stat_name.isin(cum_stats)].groupby(ix_cols).sum()\n",
    "stats = gb['stat_amount'].unstack()\n",
    "wide_stats = stats.unstack().dropna(axis=1, how='all')\n",
    "wide_stats.columns = wide_stats.columns.swaplevel()\n",
    "wide_stats = wide_stats.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break out stats by player/map\n",
    "\n",
    "gb = raw_df[raw_df.stat_name.isin(cum_stats)].groupby(['player_name'] + ix_cols).sum()\n",
    "stats = gb['stat_amount'].unstack()\n",
    "\n",
    "player_stats = stats.unstack().dropna(axis=1, how='all')\n",
    "player_stats.columns = player_stats.columns.swaplevel()\n",
    "player_stats = player_stats.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create separate dataframes for average stats\n",
    "gb = raw_df[raw_df.stat_name.isin(avg_stats | {'Time Played'})].groupby(['player_name'] + ix_cols).sum()\n",
    "\n",
    "stats = gb['stat_amount'].unstack()\n",
    "player_avg_stats = stats.unstack().dropna(axis=1, how='all')\n",
    "\n",
    "# now combine average stats per hero/map\n",
    "gb_ix = ['esports_match_id', 'map_name', 'team_name', 'hero_name']\n",
    "\n",
    "# weight averages by time played\n",
    "def weighted_sum(x):\n",
    "    weighted_df = x.drop('Time Played', axis=1).multiply(x['Time Played'], axis=0)\n",
    "    return weighted_df.sum() / x['Time Played'].sum()\n",
    "\n",
    "avg_stat_df = stats.groupby(gb_ix).apply(weighted_sum)\n",
    "\n",
    "# add time played back in as a stat\n",
    "avg_stat_df['Time Played'] = stats[['Time Played']].groupby(gb_ix).sum()\n",
    "\n",
    "# move hero name from the index to the column name\n",
    "avg_stat_df = avg_stat_df.unstack().dropna(axis=1, how='all')\n",
    "\n",
    "# put heroes as top column index and sort alphabetically\n",
    "avg_stat_df.columns = avg_stat_df.columns.swaplevel()\n",
    "avg_stat_df = avg_stat_df.sort_index(axis=1)\n",
    "\n",
    "# drop columns with only zeros\n",
    "avg_stat_df = avg_stat_df.loc[:, (avg_stat_df.fillna(0) != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove seldom-used heroes from the dataset\n",
    "\n",
    "heroes = set(wide_stats.columns.get_level_values(0))\n",
    "heroes.remove('All Heroes')\n",
    "for h in list(heroes):\n",
    "    if wide_stats[h]['Time Played'].sum() / 3600 < 3:\n",
    "        print('removing', h)\n",
    "        heroes.remove(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate stats by group of heroes. Break out stats by DPS, tank, and support.\n",
    "\n",
    "from functools import reduce\n",
    "groups = {\n",
    "    'All Tanks': {'Sigma', 'Zarya', 'Reinhardt', 'Winston', 'Orisa', 'Wrecking Ball', 'D.Va'},\n",
    "    'All DPS': {'Reaper', 'Echo', 'Widowmaker', 'Pharah', 'Tracer', 'Doomfist', 'McCree', \n",
    "                'Torbjörn', 'Sombra', 'Hanzo', 'Ashe', 'Symmetra', 'Mei', 'Genji', 'Soldier: 76'},\n",
    "    'All Supports': {'Ana', 'Zenyatta', 'Lúcio', 'Brigitte', 'Mercy', 'Moira', 'Baptiste'},\n",
    "}\n",
    "\n",
    "def create_group(data, group, name):\n",
    "    common_stats = reduce(lambda a, b: a & b, (data[h].columns for h in group))\n",
    "    out = pd.DataFrame(index=data.index)\n",
    "    data_z = data.fillna(0)\n",
    "    for s in common_stats:\n",
    "        out[name, s] = sum(data_z[h][s] for h in group)\n",
    "    return out\n",
    "\n",
    "for name, group in groups.items():\n",
    "    # drop stats if they're already there and recalculate\n",
    "    if name in wide_stats:\n",
    "        wide_stats = wide_stats.drop(name, axis=1)\n",
    "    wide_stats = pd.concat([wide_stats, create_group(wide_stats, group, name)], axis=1)\n",
    "    \n",
    "    if name in player_stats:\n",
    "        player_stats = player_stats.drop(name, axis=1)\n",
    "    player_stats = pd.concat([player_stats, create_group(player_stats, group, name)], axis=1)\n",
    "    \n",
    "print(wide_stats.shape, player_stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr, zscore\n",
    "import numpy as np\n",
    "\n",
    "# Get point-biserial correlation between one stat and wins\n",
    "def get_corr(col, filt=None):\n",
    "    if type(col) != pd.Series:\n",
    "        col = pd.Series(col)\n",
    "    \n",
    "    if filt is None:\n",
    "        filt = ~col.isnull()\n",
    "        \n",
    "    filt = filt & ~col.isnull()\n",
    "    \n",
    "    if sum(filt) < 3:\n",
    "        return None\n",
    "\n",
    "    X = zscore(col[filt])\n",
    "    y = outcomes[filt]\n",
    "    return pointbiserialr(y, X)\n",
    "\n",
    "# Print correlations for each column in a dataframe\n",
    "def print_corrs(data):\n",
    "    corrs = []\n",
    "    for stat in data.columns:\n",
    "        res = get_corr(data[stat])\n",
    "        if res is None:\n",
    "            continue\n",
    "            \n",
    "        r, p = res\n",
    "        if np.log10(p) < -1.5:\n",
    "            corrs.append((r, stat))\n",
    "\n",
    "    res = sorted(corrs, key=lambda i: -abs(i[0]))\n",
    "    for r in res:\n",
    "        print('%s: %.3f' % (r[1], r[0]))\n",
    "        \n",
    "# Change stats from cumulative to per-10-minutes\n",
    "def get_hs_per_10(hero_stats):\n",
    "    return hero_stats.apply(\n",
    "        lambda x: x.drop('Time Played') \n",
    "                  / (x['Time Played'] / 600),\n",
    "        axis=1)\n",
    "        \n",
    "    \n",
    "# Change stats from cumulative to per-10-minutes\n",
    "def get_stats_per_10(stats):\n",
    "    df = pd.DataFrame(index=stats.index, columns=stats.columns)\n",
    "    heroes = set(stats.columns.get_level_values(0))\n",
    "    for h in heroes:\n",
    "        df[h] = get_hs_per_10(stats[h])\n",
    "        \n",
    "    return df\n",
    "    \n",
    "# Print all stats for a hero, and how much each stat correlates with winning\n",
    "def print_hero_stats(hero):\n",
    "    hero_stats = wide_stats[hero]\n",
    "    hs_per_10 = get_hs_per_10(hero_stats)\n",
    "    print(hero, hero_stats['Time Played'].sum() / 3600)\n",
    "    print_corrs(hero_stats)\n",
    "    \n",
    "stats_per_10 = get_stats_per_10(wide_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_var_ratio_vs_wins(attr1, attr2=False, heroes=heroes):\n",
    "    # average per 10 minutes for a team\n",
    "    as_per_10 = get_hs_per_10(wide_stats['All Heroes'])\n",
    "\n",
    "    for h in heroes:\n",
    "        # average stats per 10 minutes for each hero\n",
    "        hs = get_hs_per_10(wide_stats[h])\n",
    "\n",
    "        if attr1 not in hs.columns:\n",
    "            continue\n",
    "\n",
    "        # compute average kill participation for the hero (fraction of total \n",
    "        # kills that the hero took part in) and correlate with win percentage\n",
    "        if attr2:\n",
    "            if attr2 not in hs.columns:\n",
    "                continue\n",
    "            res = get_corr(hs[attr1] / hs[attr2])\n",
    "        # if attr2 is not provided, compute a ratio against the team total\n",
    "        else:\n",
    "            res = get_corr(hs[attr1] / as_per_10[attr1])\n",
    "        \n",
    "        if res is None:\n",
    "            # print('** Not enough data for', h, '**')\n",
    "            continue\n",
    "\n",
    "        r, p = res\n",
    "        tp = wide_stats[h]['Time Played'].sum() / 3600\n",
    "        ci = np.log10(p)\n",
    "\n",
    "        # only print significant results\n",
    "        if len(heroes) < 5 or p < 0.05:\n",
    "            print('%s (%.0f hours): %.3f, p=%.3f' % (h, tp, r, p))\n",
    "            \n",
    "\n",
    "get_var_ratio_vs_wins(attr1='Final Blows',\n",
    "                      attr2='Eliminations',\n",
    "                      heroes=['All Supports', 'All DPS', 'All Tanks', 'All Heroes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of ultimates negated by a D.Va as a fraction of the negatable ults they faced in a round\n",
    "# (only count mei, zarya, and tracer, though hanzo is technically possible)\n",
    "\n",
    "def get_ult_negation_pct(stats):\n",
    "    wsz = stats.fillna(0)\n",
    "    series = []\n",
    "\n",
    "    for i in range(len(wsz.index)):\n",
    "        j = i + 1 if i % 2 == 0 else i - 1\n",
    "        ri = wsz.iloc[i]\n",
    "        rj = wsz.iloc[j]\n",
    "        ults_against = sum(rj[h]['Ultimates Used'] for h in ['Mei', 'Zarya', 'Tracer'])\n",
    "\n",
    "        val = np.nan\n",
    "        if ults_against > 0 and ri['D.Va']['Time Played']:\n",
    "            val = ri['D.Va']['Ultimates Negated'] / ults_against\n",
    "            #print(ri['D.Va']['Ultimates Negated'], ults_against, outcomes.iloc[i])\n",
    "\n",
    "        elif ri['D.Va']['Ultimates Negated']:\n",
    "            print(wsz.index[i],wsz.index[j], ri['D.Va']['Ultimates Negated'])\n",
    "\n",
    "        series.append(val)\n",
    "\n",
    "    return pd.Series(series, index=stats.index)\n",
    "\n",
    "print(get_corr(get_ult_negation_pct(wide_stats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common_stats = set(stats_per_10['All Heroes'].columns) & reduce(lambda i, j: i & j, (set(stats_per_10[h].columns) for h in heroes))\n",
    "\n",
    "predictive_stats = {\n",
    "    'Hero Damage Done', \n",
    "    'Barrier Damage Done', \n",
    "    'Damage - Quick Melee',\n",
    "    'Eliminations',\n",
    "    'Final Blows', \n",
    "    'Melee Final Blows', \n",
    "    'Knockback Kills', \n",
    "    'Environmental Kills',\n",
    "    'Solo Kills', \n",
    "    'Objective Kills',\n",
    "    'Multikills', \n",
    "    'Assists', \n",
    "    'Recon Assists',\n",
    "    'Offensive Assists', \n",
    "    'Defensive Assists',\n",
    "    'Healing Done',  \n",
    "    'Damage Taken',\n",
    "    'Damage Blocked', \n",
    "    'Time Alive', \n",
    "    'Deaths', \n",
    "    'Environmental Deaths',\n",
    "    'Objective Time', \n",
    "    'Time Building Ultimate',\n",
    "    'Time Holding Ultimate', \n",
    "    'Ultimates Used', \n",
    "}\n",
    "\n",
    "quick_stats = {\n",
    "    'Hero Damage Done', \n",
    "    'Eliminations',\n",
    "    'Final Blows', \n",
    "    'Solo Kills', \n",
    "    'Objective Kills',\n",
    "    'Assists', \n",
    "    'Healing Done',  \n",
    "    'Damage Taken',\n",
    "    'Damage Blocked', \n",
    "    'Deaths',\n",
    "    'Objective Time',\n",
    "    'Time Building Ultimate',\n",
    "    'Time Holding Ultimate', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratio_stat(data, s1, s2, default=None):\n",
    "    ratio = (data[s1].fillna(0) / data[s2])\n",
    "    if default:\n",
    "        return ratio.fillna(default)\n",
    "    return ratio\n",
    "\n",
    "stat_dict = {\n",
    "    'Accuracy': ('Shots Hit', 'Shots Fired'),\n",
    "    'Critical Accuracy': ('Critical Hits', 'Shots Fired'),\n",
    "    'K/D': ('Eliminations', 'Deaths'),\n",
    "    'Final Blows per Death': ('Final Blows', 'Deaths'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from scipy.special import expit\n",
    "\n",
    "def filter_and_normalize(hero_stats, ah_stats, pred_stats, filter_fraction=0.3):\n",
    "    if pred_stats is not None:\n",
    "        pred_stats = set(pred_stats) | {'Time Played'}\n",
    "        ah_stats = ah_stats[pred_stats]\n",
    "        \n",
    "    common_stats = set(pred_stats) & set(hero_stats.columns)\n",
    "    \n",
    "    # filter out maps where the hero didn't play at least a fraction of the map\n",
    "    filt = (hero_stats['Time Played'].fillna(0) > (ah_stats['Time Played'] / 6) * filter_fraction)\n",
    "    if sum(filt) < 3:\n",
    "        print('Not enough data for', stat)\n",
    "        return\n",
    "    \n",
    "    hero_stats = hero_stats[filt].fillna(0)\n",
    "    ah_stats = ah_stats[filt].fillna(0)\n",
    "    ah_stats = ah_stats.subtract(hero_stats[common_stats], fill_value=0)\n",
    "\n",
    "    # convert stats to per-10-minutes\n",
    "    ah_per_10 = get_hs_per_10(ah_stats)\n",
    "    hero_per_10 = get_hs_per_10(hero_stats)\n",
    "    \n",
    "    # add in the portion of time this hero was played as a variable\n",
    "    ah_per_10['Time Played'] = hero_stats['Time Played'] * 6 / ah_stats['Time Played']\n",
    "    return ah_per_10, hero_per_10, filt\n",
    "                                                                                    \n",
    "\n",
    "# df: full statistics data\n",
    "# hero: the hero to predict for\n",
    "# stat: the name of the statistic to predict\n",
    "def get_stat_predictor(stats, hero, stat, pred_stats=predictive_stats):\n",
    "    # filter out games where this hero wasn't played much and remove its stats from totals\n",
    "    ah_per_10, hero_per_10, filt = filter_and_normalize(stats[hero], stats['All Heroes'], pred_stats)\n",
    "    \n",
    "    if stat in stat_dict:\n",
    "        hero_per_10[stat] = get_ratio_stat(stats[hero][filt], *stat_dict[stat])\n",
    "        hero_per_10.fillna(hero_per_10[stat_dict[stat][0]])\n",
    "        \n",
    "    # try to predict this stat using the rest of the team's performance\n",
    "    X = ah_per_10\n",
    "    y = hero_per_10[stat]\n",
    "    reg = LinearRegression().fit(X, y)\n",
    "    return reg, X, y, filt\n",
    "\n",
    "\n",
    "stat_pred_cache = {}\n",
    "\n",
    "# instead of recalculating, pull the cached value when available\n",
    "def get_stat_predictor_cache(data, hero, stat, pred_stats=predictive_stats):\n",
    "    if (hero, stat) in stat_pred_cache:\n",
    "        return stat_pred_cache[(hero, stat)]\n",
    "    \n",
    "    res = get_stat_predictor(data, hero, stat, pred_stats=pred_stats)\n",
    "    stat_pred_cache[(hero, stat)] = res\n",
    "    return res\n",
    "\n",
    "# hero = 'Reinhardt'\n",
    "# for stat in wide_stats[hero].columns:\n",
    "#     if stat == 'Time Played':\n",
    "#         continue\n",
    "#     stat_reg, X, y, filt = get_stat_predictor(wide_stats, hero, stat)\n",
    "#     print()\n",
    "#     print(stat)\n",
    "#     print(stat_reg.score(X, y))\n",
    "#     print(pointbiserialr(outcomes[filt], y - stat_reg.predict(X)))\n",
    "\n",
    "   \n",
    "#     res = []\n",
    "#     for i in range(len(X)):\n",
    "#         pred = stat_reg.predict([X.iloc[i]])[0]\n",
    "#         res.append((pred - y[i], X[stat].iloc[i], pred, y[i], X.index[i]))\n",
    "\n",
    "#     res = list(sorted(res))#[::-1]\n",
    "#     for i in range(10):\n",
    "#         print(res[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_stat_win_predictor(X, y, filter_nan=False):\n",
    "    if filter_nan:\n",
    "        filt = ~np.isnan(X)\n",
    "        X = X[filt]\n",
    "        y = y[filt]\n",
    "        \n",
    "    else:\n",
    "        filt = np.array([True] * len(y))\n",
    "    \n",
    "    # now use it to predict the chance of winning\n",
    "    logreg = LogisticRegression(random_state=0).fit(X, y)\n",
    "    \n",
    "    # plot the points\n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    plt.scatter(X.ravel(), y, color='black', zorder=20)\n",
    "\n",
    "    # plot some histograms\n",
    "#     n_bins = 10\n",
    "#     bin_width = (X.max() - X.min()) / n_bins\n",
    "#     bins, edges = np.histogram(X, bins=n_bins, range=(X.min(), X.max()))\n",
    "#     win_bins, _ = np.histogram(X[y], bins=n_bins, range=(X.min(), X.max()))\n",
    "#     loss_bins, _ = np.histogram(X[~y], bins=n_bins, range=(X.min(), X.max()))\n",
    "#     win_bar = [win_bins[i] / bins[i] for i in range(n_bins)]\n",
    "#     loss_bar = [loss_bins[i] / bins[i] for i in range(n_bins)]\n",
    "    \n",
    "#     locs = [(edges[i] + edges[i+1]) / 2 for i in range(n_bins)]\n",
    "    \n",
    "#     plt.bar(locs, loss_bar, width=bin_width, color='gray')\n",
    "#     plt.bar(locs, win_bar, bottom=loss_bar, width=bin_width, color='green')\n",
    "\n",
    "    # plot the loss function\n",
    "    X_test = np.linspace(X.min(), X.max(), 300)\n",
    "    loss = expit(X_test * logreg.coef_ + logreg.intercept_).ravel()\n",
    "    plt.plot(X_test, loss, color='red', linewidth=3)\n",
    "    plt.show()\n",
    "    \n",
    "    return logreg, X, y, filt\n",
    "\n",
    "\n",
    "def get_stat_independence(hero, stats):\n",
    "    # stats must be raw, not per-10\n",
    "    predictors = {}\n",
    "    for stat in stats[hero].columns:\n",
    "        if stat == 'Time Played':\n",
    "            continue\n",
    "        \n",
    "        res = get_stat_predictor(stats, hero, stat)\n",
    "        if res is None:\n",
    "            continue\n",
    "            \n",
    "        stat_reg, X, y, filt = res\n",
    "        stat_score = stat_reg.score(X, y)\n",
    "        predictors[stat] = stat_reg\n",
    "        \n",
    "        print('%s: %.3f predicted by team' % (stat, stat_score))\n",
    "        \n",
    "        # figure out how much the stat predicts team wins\n",
    "        r, p = get_corr(y, filt)\n",
    "        \n",
    "        if p < 0.05:\n",
    "            print('Predictive power: %.3f, p=%.3f' % (r, p))\n",
    "        else:\n",
    "            print('Stat does not correlate with wins')\n",
    "        \n",
    "    return predictors\n",
    "\n",
    "#get_stat_independence('Lúcio', stats)\n",
    "predictors = get_stat_independence('D.Va', wide_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logreg_hero(hero, stats):\n",
    "    filt = stats[hero, 'Time Alive'] > 0\n",
    "    \n",
    "    columns = []\n",
    "    for c in stats[hero].columns:\n",
    "        cor = get_corr(stats[hero, c])\n",
    "        if cor is None:\n",
    "            continue\n",
    "        r, p = cor\n",
    "        if p < 0.05 and r > 0.1:\n",
    "            columns.append(c)\n",
    "            \n",
    "    print(columns)\n",
    "    X = stats[hero][columns].loc[filt].fillna(0)\n",
    "    y = outcomes[filt]\n",
    "    logreg = LogisticRegression(random_state=0).fit(X, y)\n",
    "    print(logreg.score(X, y))\n",
    "\n",
    "#get_logreg_hero('D.Va', stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotate(fig, ax, scatters, labels):\n",
    "    annot = ax.annotate(\"\", xy=(0, 0), xytext=(20, 20),textcoords=\"offset points\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"->\"))\n",
    "    annot.set_visible(False)\n",
    "\n",
    "    def update_annot(sci, pi):\n",
    "        pos = scatters[sci].get_offsets()[pi]\n",
    "        annot.xy = pos\n",
    "        annot.set_text(labels[sci][pi])\n",
    "\n",
    "    def hover(event):\n",
    "        vis = annot.get_visible()\n",
    "        if event.inaxes == ax:\n",
    "            for sci, sc in enumerate(scatters):\n",
    "                cont, ind = sc.contains(event)\n",
    "                if cont:\n",
    "                    update_annot(sci, ind['ind'][0])\n",
    "                    annot.set_visible(True)\n",
    "                    fig.canvas.draw_idle()\n",
    "                    break\n",
    "            else:\n",
    "                if vis:\n",
    "                    annot.set_visible(False)\n",
    "                    fig.canvas.draw_idle()\n",
    "\n",
    "    return fig.canvas.mpl_connect(\"motion_notify_event\", hover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "\n",
    "def get_average(data, stat):\n",
    "    stat_cols = stat_dict.get(stat)\n",
    "    \n",
    "    # this is a regular counting stat\n",
    "    if stat_cols is None:\n",
    "        return data[stat].sum() * 600 / data['Time Played'].sum()\n",
    "    \n",
    "    # this is a ratio stat\n",
    "    s1, s2 = stat_cols\n",
    "    return data[s1].sum() / data[s2].sum()\n",
    "\n",
    "\n",
    "def get_player_stat(player, hero, stat, plot=False):\n",
    "    # get raw data for maps where the player played the hero\n",
    "    player_hero_df = player_stats.loc[player][hero]\n",
    "    player_hero_df = player_hero_df[~player_hero_df['Time Played'].isnull()]\n",
    "    \n",
    "    # find average stats for the player and the league on this hero\n",
    "    player_avg = get_average(player_hero_df, stat)\n",
    "    league_avg = get_average(wide_stats[hero], stat)\n",
    "    print('Average %s: %.3f (league average: %.3f)' % (stat, player_avg, league_avg))\n",
    "\n",
    "    # get everyone else's stats for each map in our dataset\n",
    "    match_stats = wide_stats.loc[player_hero_df.index]\n",
    "    ah_per_10, player_per_10, filt = filter_and_normalize(player_hero_df, match_stats['All Heroes'], \n",
    "                                                          predictive_stats, filter_fraction=0.2)\n",
    "\n",
    "    # if this is a ratio stat (like accuracy or k/d), do that computation now\n",
    "    if stat in stat_dict:\n",
    "        player_per_10[stat] = get_ratio_stat(player_hero_df, *stat_dict[stat])\n",
    "        player_per_10.fillna(player_per_10[stat_dict[stat][0]])\n",
    "\n",
    "    # get the model that will predict a hero's stats given stats from the rest of the team\n",
    "    reg, X, y, _ = get_stat_predictor_cache(\n",
    "        wide_stats, hero, stat, pred_stats=predictive_stats)\n",
    "    \n",
    "    # how much is this stat determined by the rest of the team?\n",
    "    print('Predicted by other stats: %.3f' % reg.score(X, y))\n",
    "    \n",
    "    # figure out what this player's stats should have been with our model\n",
    "    preds = reg.predict(ah_per_10)\n",
    "\n",
    "    # by how much did this player over/underperform in each map?\n",
    "    vals = (player_per_10[stat] - preds)\n",
    "    \n",
    "    # how many times did they overperform?\n",
    "    maps_above_expected = 100 * sum(vals > 0) / len(vals)\n",
    "    \n",
    "    # weight values by time played for each map\n",
    "    weights = player_hero_df['Time Played'][filt]\n",
    "    \n",
    "    # find mean and standard dev\n",
    "    dif_avg = np.average(vals, weights=weights)\n",
    "    dif_std = np.sqrt(np.cov(vals / preds, aweights=weights)) * 100\n",
    "    \n",
    "    print('%.1f%% of maps above expected, average difference of %.3f (std=%.1f%%)' % \n",
    "          (maps_above_expected, dif_avg, dif_std))\n",
    "\n",
    "    if plot:\n",
    "        # plot things\n",
    "        # use red colors for good, blue for bad\n",
    "        cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"RedGreen\", [\"xkcd:red\", \"xkcd:green\"])\n",
    "\n",
    "        # scale the color intensity based on time played\n",
    "        sigma = (y - reg.predict(X)).std()\n",
    "        norm = matplotlib.colors.Normalize(vmin=sigma * -3, \n",
    "                                           vmax=sigma * 3)\n",
    "\n",
    "        # create the x=y line\n",
    "        maxval = max(player_per_10[stat].max(), preds.max()) * 1.2\n",
    "        plt.plot([0, maxval], [0, maxval], color='k')\n",
    "\n",
    "        # now plot the points\n",
    "        plt.scatter(preds, player_per_10[stat], s=weights / 4, color=cmap(norm(vals)))\n",
    "\n",
    "    preds = pd.Series(preds, index=player_per_10[stat].index, name='value')\n",
    "    results = player_per_10[stat].rename('value')    \n",
    "    return preds, results, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ix_cols = ['esports_match_id', 'map_name', 'team_name', 'player_name']\n",
    "\n",
    "def get_best_player(hero, stat, min_time=1, plot=True):\n",
    "    players = set(player_stats.index.get_level_values(0))\n",
    "    player_preds = pd.DataFrame()\n",
    "    player_results = pd.DataFrame()\n",
    "    \n",
    "    for player in players:\n",
    "        # must have at least 1 hour played\n",
    "        time_played = player_stats.loc[player][hero]['Time Played'].sum() / 3600\n",
    "        if time_played > min_time:\n",
    "            print()\n",
    "            print('%s, %.1f hours on %s' % (player, time_played, hero))\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        preds, results, weights = get_player_stat(player, hero, stat)\n",
    "        player_results = player_results.append(\n",
    "            results.to_frame().assign(weight=weights).reset_index().assign(player_name=player))\n",
    "        player_preds = player_preds.append(\n",
    "            preds.to_frame().assign(weight=weights).reset_index().assign(player_name=player))\n",
    "        \n",
    "        best = (results - preds).argmax()\n",
    "        worst = (results - preds).argmin()\n",
    "        print('Best game: %s, %.3f (%+.3f)' % (results.to_frame().iloc[best][:2], results.iloc[best], (results-preds).iloc[best]))\n",
    "        print('Worst game: %s, %.3f (%+.3f)' % (results.to_frame().iloc[worst][:2], results.iloc[worst], (results-preds).iloc[worst]))\n",
    "    \n",
    "    player_preds.set_index(player_ix_cols, inplace=True)\n",
    "    player_results.set_index(player_ix_cols, inplace=True)\n",
    "    \n",
    "    if plot:\n",
    "        # plot each performance\n",
    "        # use red colors for good, blue for bad\n",
    "        cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"RedGreen\", [\"xkcd:red\", \"xkcd:green\"])\n",
    "\n",
    "        # scale the color intensity based on value above or below expected\n",
    "        diffs = player_results.value - player_preds.value\n",
    "        sigma = np.sqrt(np.cov(diffs, aweights=player_results.weight))\n",
    "        norm = matplotlib.colors.Normalize(vmin=sigma * -3, \n",
    "                                           vmax=sigma * 3)\n",
    "\n",
    "        # create the x=y line\n",
    "        maxval = max(player_results['value'].max(), player_preds['value'].max()) * 1.2\n",
    "        plt.plot([0, maxval], [0, maxval], color='k')\n",
    "\n",
    "        # now plot the points\n",
    "        fig, ax = plt.subplots()\n",
    "        sc = plt.scatter(player_preds['value'], player_results['value'], \n",
    "                         s=player_results['weight'] / 4, \n",
    "                         color=cmap(norm(diffs)))\n",
    "        labels = ['\\n'.join([str(i[0]), i[1], i[3]]) for i in list(player_results.index)]\n",
    "        cid = create_annotate(fig, ax, [sc], labels=[labels])\n",
    "        plt.show()\n",
    "        \n",
    "    return player_preds, player_results\n",
    "    \n",
    "def get_all_player_stats(player, hero):\n",
    "    stats = wide_stats[hero].columns\n",
    "    for stat in stats:\n",
    "        res = get_corr(stats_per_10[hero][stat])\n",
    "        if res is None:\n",
    "            continue\n",
    "        r, p = res\n",
    "        if r < 0.05 or p > 0.05:\n",
    "            continue\n",
    "        preds, results = get_player_stat(player, hero, stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dps = list(groups['All DPS'])\n",
    "plt.bar(dps, [sum(wide_stats[h]['Time Played'].fillna(0)) for h in dps])\n",
    "print(wide_stats['Mei'].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preds, results = get_best_player('Genji', 'Eliminations', min_time=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wide_stats.loc[34492, \"King's Row\"]['Echo'])\n",
    "outcomes[34492, \"King's Row\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weighted_avg = lambda x: (x['value'] * x['weight']).sum() / x['weight'].sum()\n",
    "\n",
    "avg = preds.groupby('player_name').apply(weighted_avg)\n",
    "\n",
    "dif_df = results.copy()\n",
    "dif_df['value'] -= preds['value']\n",
    "diff = dif_df.groupby('player_name').apply(weighted_avg)\n",
    "\n",
    "weights = dif_df['weight'].groupby('player_name').sum()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sc = plt.scatter(avg, diff, s=weights / 40)\n",
    "cid = create_annotate(fig, ax, [sc], labels=[avg.index])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
